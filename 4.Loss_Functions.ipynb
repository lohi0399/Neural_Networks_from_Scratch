{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function --> Key to optimize our network\n",
    "\n",
    "# 1. Categorical Cross Entropy ---> Generally used for classification\n",
    "\n",
    "# Say I have the the following scenario where in the output values are [Red, Green , Blue], and we have the following batch of data:\n",
    "import numpy as np \n",
    "\n",
    "class Loss:\n",
    "    def calculate(self,output,y):\n",
    "        sample_losses = self.forward(y,output) \n",
    "        self.mean_loss = np.mean(sample_losses)\n",
    "        return self.mean_loss\n",
    "        \n",
    "        \n",
    "class CCE(Loss):\n",
    "    def forward(self,y_pred,y_true):\n",
    "        y_pred_clip = np.clip(y_pred,1e-7,1-1e-7)\n",
    "        \n",
    "        \n",
    "        if len(y_true.shape) == 1: # Only categorical labels are given [0,1,1,....]\n",
    "            print('Target indices given for each output')\n",
    "            self.loss = -np.log(y_pred_clip[range(len(y_true),), y_true])\n",
    "            \n",
    "        elif len(y_true.shape) == 2: # For one-hot encoded values\n",
    "            print('Target is one-hot encoded')\n",
    "            masked_values = np.sum(y_true*y_pred_clip,axis=1,keepdims=True)\n",
    "            self.loss = -np.log(masked_values)\n",
    "        \n",
    "        return self.loss\n",
    "            \n",
    "ce = CCE()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target is one-hot encoded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38506092872941844"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = np.array([[0.7,0.1,0.2],\n",
    "           [0.1,0.5,0.4],\n",
    "           [0.02,0.9,0.08]])\n",
    "\n",
    "true_labels = np.array([[1,0,0],\n",
    "               [0,1,0],\n",
    "               [0,1,0]]) # One hot encoded values\n",
    "\n",
    "ce.calculate(outputs,true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38506092872941844"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce.mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " NOTE: The base of the log is generally taken as 'e'. Even if we take another base it doesn't really matter since any base can be represented in terms of 'e' and base 2 basically turn out be the scaling factor. I only advantage of using base 2 is that it is faster to compute, but anyway CE is never the cotly part of NN for it not something to be overly concerend with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target indices given for each output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.35667494, 0.69314718, 0.10536052])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fancy indexing in NumPy\n",
    "\n",
    "softmax_outputs = np.array([\n",
    "    [0.7, 0.1, 0.2],  # Row 0\n",
    "    [0.1, 0.5, 0.4],  # Row 1\n",
    "    [0.02, 0.9, 0.08] # Row 2\n",
    "])\n",
    "\n",
    "class_targets = np.array([0, 1, 1]) # Target indices given\n",
    "ce.forward(softmax_outputs,class_targets)\n",
    "ce.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38506092872941844"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce.mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
